# Issue #004: Ollama連携モジュールの実装

## タイトル
Ollama連携モジュールの実装

## 概要
OllamaのOpenAI互換APIを使用してLLM推論を実行する連携モジュールを実装する。複数モデルの切り替え、エラーハンドリング、レスポンス処理を含む。

## 詳細
- Ollama OpenAI互換API（/v1/chat/completions）への接続
- 複数LLMモデルの切り替え機能（例：gpt-oss:20b）
- LLMリクエスト/レスポンス処理
- 接続エラー、タイムアウト処理
- 統計データ（レスポンス時間、LLMエラー率）の記録
- 設定による接続先変更対応（環境変数、設定ファイル）

## 受け入れ条件
- [ ] OllamaのOpenAI互換APIに正常に接続できる
- [ ] 複数モデルの切り替えが動作する
- [ ] エラーハンドリングが適切に実装されている
- [ ] レスポンス時間が正確に計測される
- [ ] 設定による接続先変更が可能

## 関連仕様
- LLM 運用要件（Ollama 前提）
- 運用・構成管理（モデル切替）
- ロギング／観測性（LLM エラー率）

# sub-issue

## Task 1: OllamaClientクラスの実装

### 実装ステップ（MVP段階：基本機能のみ）
- **OllamaClientクラスの作成**
  - OpenAI互換API接続とリクエスト処理の基盤クラス
- **接続機能の実装**
  - HTTP接続と基本タイムアウト管理（社内ネットワーク対応）
- **chat_completions関数の実装**
  - OpenAI互換形式でのLLM推論実行
- **基本エラーハンドリング機能の実装**
  - 接続エラー、タイムアウト、APIエラーの基本処理
- **レスポンス時間計測機能**
  - リクエスト処理時間の基本計測（品質ゲート要件）

### 外部公開時の追加実装（Phase 2）
- **詳細エラー率計測機能**: エラー種別ごとの統計記録とエラー率算出
- **HTTPS接続対応**: TLS/SSL通信でのセキュアな接続

### ユニットテスト
- 正常なchat_completionsリクエストのテスト
- 接続エラー時のエラーハンドリングテスト
- エラー率計算の正確性テスト
- レスポンス時間計測の精度テスト

## Task 2: モデル切り替え機能の実装

### 実装ステップ
- get_available_models関数の実装
  - Ollama APIからの利用可能モデル一覧取得
- switch_model関数の実装
  - 指定モデルへの切り替えと状態管理
- validate_model関数の実装
  - モデル名妥当性検証と存在確認
- モデル情報管理機能
  - 現在使用モデルの記録と履歴管理

### ユニットテスト
- 利用可能モデル一覧取得のテスト
- 正常なモデル切り替えのテスト
- 存在しないモデル指定時のエラーテスト

